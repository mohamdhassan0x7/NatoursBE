import requests
import json
import sys

# print("{'role': 'assistant', 'content': \"  Hello! Of course, I'd be happy to help you find the best product for your needs. Can you please tell me a bit more about what you're looking for? What type of laptop, mobile phone, or other product are you interested in? And what are your specific needs and requirements? This will help me provide you with more tailored recommendations and comparisons.\"}\r\n")


messeges = []
messeges.append({
            "role": "system",
            "content": """You are mr.Alex, an expert technical assistant who is helping a customer to find best product (laptop, mobile phones, etc) for their needs,
                        and answer his technical questions, and provide him comparisons if needed,make your answers to the point 
                        If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. 
                        If you don't know the answer to a question, please don't share false information."""
        })



def req (prompt):
    messeges.append({"role":"user", "content" : prompt})
    p = "[INST]" + prompt+ "[/INST]"
    endpoint = 'https://api.together.xyz/v1/chat/completions'
    res = requests.post(endpoint, json={
        "model": "meta-llama/Llama-2-7b-chat-hf",
        "max_tokens": 250,
        # "prompt": p,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": [
            "[/INST]",
            "</s>"
        ],
        "messages": messeges,
        # "stream": True,
    }, headers={
        "Authorization": "Bearer c596c0e2ca7bee45c6db99bf5c39e8b84f3f3c124cf078c272376e3468f1c627",
    })
    return res        


def Llama (input):
    res = req(input)
    # print(res.text)
    res = json.loads(res.text)
    response = res["choices"][0]["message"]
    # print(response)
    # print(type(response))
    messeges.append(response)
    print(json.dumps(response))

Llama(sys.argv[1]) 


# Llama("Hello, can you help me?")
